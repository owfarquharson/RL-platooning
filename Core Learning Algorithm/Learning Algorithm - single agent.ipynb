{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Algorithm - Single agent\n",
    "\n",
    "This script contains the algorithm referred to as 'Algorithm 3: Model free Q-Function Estimation and Policy Improvement' in the report\n",
    "\n",
    "### 'Continuous_car' \n",
    "\n",
    "Instantiated with a controller K, and boolean variables defining whether you want system noise or controller noise\n",
    "\n",
    "##### 'MatrixMaker'\n",
    "\n",
    "    Will return 3 matrices used for the computation of the Q-function approximation weights\n",
    "\n",
    "##### 'LSOptimiser'\n",
    "\n",
    "    Uses the three above matrices to compute and return the weight vector\n",
    "\n",
    "##### 'PolicyMaximiser'\n",
    "\n",
    "    Uses the learned weight vector to calculate the new controller\n",
    "\n",
    "### 'PolicyImprovementAlgo'\n",
    "\n",
    "Carries out a desired number of updates of the controller by calling the above functions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# class for the agent\n",
    "class Continuous_car():\n",
    "\n",
    "    \n",
    "    def __init__(self,K,noisy_model = False, noisy_controller=False):\n",
    "        \n",
    "        #system\n",
    "        self.A = np.array([[1,1],[0, 1]])\n",
    "        self.B = np.array([[0.5],[1]])\n",
    "\n",
    "        #cost matrices\n",
    "        self.E = np.array([[1,0],[0, 0.5]])\n",
    "        self.F = np.array([1])\n",
    "\n",
    "        # Arbitrary gain choice used (stability checked)\n",
    "        self.K = K\n",
    "        \n",
    "        # Optimal Gains found using dLQR on Matlab:\n",
    "        # K_Optimal = [ 0.4634, 1.0170 ]\n",
    "\n",
    "        self.disc_fact = 0.99\n",
    "        self.n_states = 2\n",
    "        \n",
    "        if noisy_model == True:\n",
    "            self.sigma_model = 0.25\n",
    "        else:\n",
    "            self.sigma_model = 0\n",
    "            \n",
    "        self.sigma_controller = 0.2\n",
    "        self.noisy_controller = noisy_controller\n",
    "    \n",
    "    def GetPolicyInput(self,x):\n",
    "        #For a given state, return the input u according to a defined policy\n",
    "        # x: 2x1 array\n",
    "        # K: 1x2 array\n",
    "        \n",
    "        inp = np.matmul(self.K,x)[0] #scalar\n",
    "        \n",
    "        if self.noisy_controller:\n",
    "            inp += self.GetControllerNoise() #scalar\n",
    "        \n",
    "        return inp #scalar\n",
    "    \n",
    "    def GetControllerNoise(self):\n",
    "        # returns scalar value of noise\n",
    "        \n",
    "        contr_noise = self.sigma_controller * np.random.randn(1)[0] # scalar\n",
    "        \n",
    "        return contr_noise\n",
    "    \n",
    "    def GetCost(self, x, u):\n",
    "        #For a given state, return the one step cost of this new state\n",
    "        # x is a 2x1 array\n",
    "        # u is a scalar\n",
    "        \n",
    "        # x'Ex\n",
    "        cost1 = np.matmul(np.matmul(x.transpose(),self.E),x)[0][0]\n",
    "        \n",
    "        # u'Fu\n",
    "        cost2 = u*u*self.F[0]\n",
    "        \n",
    "        return cost1+cost2 #scalar\n",
    "        \n",
    "    def GetNoise(self):\n",
    "        # Returns a vector with noise for the model only for velocity state\n",
    "        \n",
    "        w = np.array([0,self.sigma_model*np.random.randn(1)[0]]).reshape(2,1)\n",
    "        \n",
    "        return w # 2x1 array\n",
    "    \n",
    "    def GetNextState(self,current_state,current_input):\n",
    "        # returns the next state, x using the model given a current state and input           \n",
    "        \n",
    "        x_next_1 = np.matmul(self.A,current_state)\n",
    "        \n",
    "        x_next_2 = self.B * current_input\n",
    "        x_next_3 = self.GetNoise()\n",
    "        #pdb.set_trace()\n",
    "        x_next = x_next_1 + x_next_2 + x_next_3\n",
    "        return x_next\n",
    "    \n",
    "\n",
    "    def RunEpisode(self, episode_length, state_initial):\n",
    "        #function will return lists of the states, inputs and costs for a trajectory of chosen length given an initial state\n",
    "        '''\n",
    "        length: integer\n",
    "        state_initial: list form, e.g. [3,2] for position of 3 and velocity of 2\n",
    "        '''\n",
    "\n",
    "        x = np.array(state_initial).reshape(2,1)\n",
    "\n",
    "        state_list = [x]\n",
    "        cost_list = []\n",
    "        input_list = []\n",
    "        pos_list = [x[0][0]]\n",
    "        vel_list = [x[1][0]]\n",
    "            \n",
    "\n",
    "\n",
    "       \n",
    "        #input_list.append(sys.GetInput(x))\n",
    "\n",
    "        for k in range(episode_length):\n",
    "            \n",
    "            u = self.GetPolicyInput(x)\n",
    "                \n",
    "\n",
    "            input_list.append(u)\n",
    "            \n",
    "            #pdb.set_trace()\n",
    "\n",
    "            x = self.GetNextState(x,u)\n",
    "            cost = self.GetCost(x,u)\n",
    "\n",
    "            state_list.append(x)\n",
    "            cost_list.append(cost)\n",
    "\n",
    "\n",
    "            pos_list.append(x[0][0])\n",
    "            vel_list.append(x[1][0])\n",
    "            \n",
    "            #pdb.set_trace()\n",
    "\n",
    "        return state_list, cost_list, input_list, pos_list, vel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatrixMaker(sys, number_of_episodes=100, episode_length=10):\n",
    "    '''\n",
    "    For the defined system, this will run a certain number of episodes from random \n",
    "    initial states and return the matrices used for LSTD estimation of the value function\n",
    "    \n",
    "    The output for this version will give a Theta vector of 6 elements which are the coefficients for the terms:\n",
    "    \n",
    "    x1^2\n",
    "    x1 * x2\n",
    "    x1 * u\n",
    "    x2^2\n",
    "    x2 * u\n",
    "    u^2\n",
    "    1 (constant)\n",
    "    '''\n",
    "    df = sys.disc_fact\n",
    "    \n",
    "    X1_list = []\n",
    "    X2_list = []\n",
    "    Costs_list = []\n",
    "    Inputs_list = []\n",
    "    \n",
    "    mu_position = 0\n",
    "    sigma_position = 10\n",
    "    mu_velocity = 0\n",
    "    sigma_velocity = 2\n",
    "\n",
    "    \n",
    "    def GetRandomSample():\n",
    "        #returns a random initial state\n",
    "        x1 = sigma_position * np.random.randn(1)[0] + mu_position\n",
    "        x2 = sigma_velocity * np.random.randn(1)[0] + mu_velocity\n",
    "        \n",
    "        return [x1,x2]\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    for episode in range(number_of_episodes):\n",
    "        \n",
    "        x_init = GetRandomSample()\n",
    "        \n",
    "        state_list, cost_list, input_list, pos_list, vel_list = sys.RunEpisode(episode_length,x_init)\n",
    "        \n",
    "        X1_list.append(pos_list)\n",
    "        X2_list.append(vel_list)\n",
    "        Costs_list.append(cost_list)\n",
    "        Inputs_list.append(input_list)\n",
    "        \n",
    "        if episode%1000 == 0:\n",
    "            print(f'...running, iteration {episode} completed')\n",
    "        \n",
    "    # The lists for states, costs and inputs are now compiled\n",
    "    \n",
    "    # Each list contains p episodes\n",
    "    # Each episode contains k transitions and k+1 states\n",
    "    # There are therefore in total, p*k transitions = N\n",
    "    \n",
    "    transitions_done = 0\n",
    "    for episode in Costs_list:\n",
    "        transitions_done += len(episode)\n",
    "        \n",
    "    N = transitions_done\n",
    "    \n",
    "    Beta_k = np.zeros((7,N))\n",
    "    Beta_kplus1 = np.zeros((7,N))\n",
    "    C_k = np.zeros((N)).reshape(N,1)\n",
    "    \n",
    "    transition_counter = 0\n",
    "    skipped_samples = 0\n",
    "    # for every transition, we can create an equation and hence populate a column of our Beta matrices (and row of Ck)\n",
    "    \n",
    "    for idx_episode,episode in enumerate(Costs_list):\n",
    "        for idx_transition,transition in enumerate(episode):\n",
    "            \n",
    "           \n",
    "            x1_current = X1_list[idx_episode][idx_transition]\n",
    "            x1_next = X1_list[idx_episode][idx_transition+1]\n",
    "            \n",
    "            x2_current = X2_list[idx_episode][idx_transition]\n",
    "            x2_next = X2_list[idx_episode][idx_transition+1]\n",
    "            \n",
    "            input_current = Inputs_list[idx_episode][idx_transition]\n",
    "            \n",
    "            x_next_vector = np.array([[x1_next],[x2_next]])\n",
    "            \n",
    "            input_next = np.matmul(sys.K,x_next_vector)  \n",
    "            \n",
    "            trans_cost = Costs_list[idx_episode][idx_transition]\n",
    "            \n",
    "            \n",
    "            #Populate Beta_k matrix\n",
    "            #x1^2\n",
    "            Beta_k[0][transition_counter] = x1_current * x1_current\n",
    "            #x1 * x2\n",
    "            Beta_k[1][transition_counter] = x1_current * x2_current\n",
    "            #x1 * u\n",
    "            Beta_k[2][transition_counter] = x1_current * input_current\n",
    "            #x2^2\n",
    "            Beta_k[3][transition_counter] = x2_current * x2_current\n",
    "            #x2* u\n",
    "            Beta_k[4][transition_counter] = x2_current * input_current\n",
    "            #u^2\n",
    "            Beta_k[5][transition_counter] = input_current * input_current\n",
    "            #1\n",
    "            Beta_k[6][transition_counter] = 1\n",
    "            \n",
    "            \n",
    "            #Populate Beta_k+1\n",
    "           #x1^2\n",
    "            Beta_kplus1[0][transition_counter] = df* x1_next * x1_next\n",
    "            #x1 * x2\n",
    "            Beta_kplus1[1][transition_counter] = df* x1_next * x2_next\n",
    "            #x1 * u\n",
    "            Beta_kplus1[2][transition_counter] = df* x1_next * input_next\n",
    "            #x2^2\n",
    "            Beta_kplus1[3][transition_counter] = df* x2_next * x2_next\n",
    "            #x2* u\n",
    "            Beta_kplus1[4][transition_counter] = df* x2_next * input_next\n",
    "            #u^2\n",
    "            Beta_kplus1[5][transition_counter] = df* input_next * input_next\n",
    "            #1\n",
    "            Beta_kplus1[6][transition_counter] = df* 1\n",
    "            \n",
    "            \n",
    "            #populate Ck\n",
    "            C_k[transition_counter] = trans_cost\n",
    "            \n",
    "            transition_counter +=1\n",
    "            \n",
    "        #pdb.set_trace()\n",
    "            \n",
    "    if transition_counter != transitions_done:\n",
    "        print('Error!!! Matrices do not match!')\n",
    "    print(f'{skipped_samples} samples were skipped')\n",
    "    \n",
    "    return Beta_k, Beta_kplus1, C_k\n",
    "\n",
    "\n",
    "def LSOptimiser(sys, A,B,C):\n",
    "    '''\n",
    "    Takes in matrices A,B and vector C from 'Matrix Maker' and returns the estimated value function weights \n",
    "    '''\n",
    "    \n",
    "    # V_hat = (A* (A-B)_t)^-1  *  A   *  C\n",
    "    \n",
    "    #a = (A-B)' \n",
    "    a = (A-B)\n",
    "    a = a.transpose()\n",
    "    \n",
    "    #b = A* (A-B)_t\n",
    "    b = np.matmul(A,a)\n",
    "    \n",
    "    c = np.matmul(A,C)\n",
    "    \n",
    "        \n",
    "    # Theta = (A* (A-B)_t)^-1  *  A   *  C \n",
    "    Theta = np.linalg.solve(b,c)\n",
    "    \n",
    "    return Theta\n",
    "\n",
    "def PolicyMaximiser(Theta):\n",
    "    # for a found theta (coefficients of the Q function), this will minimise Q over u to find the optimal gains, K\n",
    "    \n",
    "    k_1 = Theta[2]/(2*Theta[5])\n",
    "    k_2 = Theta[4]/(2*Theta[5])\n",
    "    \n",
    "    K_updated = -np.array([k_1[0],k_2[0]])\n",
    "    \n",
    "    return K_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PolicyImprovementAlgo(K_initial=np.array([-1, -1.6]),i=5000,T=50,k=5):\n",
    "    '''\n",
    "    Function that will take an initial controller gain in the form above:\n",
    "     - simulate many trajectories\n",
    "     - compute the action value function using LS (Q function)\n",
    "     - minimises over the action space to find a new improved policy \n",
    "     - carries out the algo again to improve upon this controller for as many updates as desired\n",
    "     \n",
    "     Repeat the above for a specified number of steps until optimal gains are found\n",
    "    \n",
    "    # i: number of episodes (samples) run before improvement\n",
    "    # T: length (in time steps) of each episode\n",
    "    # k: number of policy improvements  \n",
    "    '''\n",
    "    \n",
    "    K_stored = [K_initial]\n",
    "    K = K_initial\n",
    "    t=0\n",
    "    \n",
    "    while t<k:\n",
    "        \n",
    "        print(f'K currently is {K}')\n",
    "        sys = Continuous_car(K, True,True)\n",
    "        print(sys.K)\n",
    "        \n",
    "        Bk, Bk1, Ck = MatrixMaker(sys, number_of_episodes=i,episode_length=T)\n",
    "\n",
    "        Theta, _, __ = LSOptimiser(sys, Bk, Bk1, Ck)\n",
    "\n",
    "        K_new = PolicyMaximiser(Theta)\n",
    "\n",
    "        K_stored.append(K_new)\n",
    "        \n",
    "        t += 1\n",
    "        K = K_new\n",
    "        print(f'\\nRunning, now onto iteration {t}')\n",
    "            \n",
    "    print('All done!')        \n",
    "    return K_stored #returns list of controllers\n",
    "\n",
    "\n",
    "# The following functions are used to extract the elements of the gains from the list and plot them\n",
    "\n",
    "def GainExtractor(Klist):\n",
    "    K1 = []\n",
    "    K2 = []\n",
    "    for i,val in enumerate(Klist):\n",
    "        K1.append(Klist[i][0])\n",
    "        K2.append(Klist[i][1])\n",
    "    return K1, K2\n",
    "\n",
    "def PlotGains(LoK, save=False, figname=None):\n",
    "    \n",
    "    K1,K2 = GainExtractor(LoK)\n",
    "    K1_opt = -0.4634*np.ones(len(K1))\n",
    "    K2_opt = -1.0170*np.ones(len(K2))\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(dpi = 150)\n",
    "    axes=fig.add_axes([0,0,1,1])\n",
    "\n",
    "    X = range(len(K1))\n",
    "\n",
    "    axes.plot(X,K1,'tab:blue',label='K[1]')\n",
    "    axes.plot(X,K1_opt,'tab:red', linewidth=0.75)\n",
    "    axes.plot(X,K2,'tab:green',label='K[2]')\n",
    "    axes.plot(X,K2_opt,'tab:red', linewidth=0.75, label='LQR optimal gain')\n",
    "    axes.set_xlabel('Iteration Number')\n",
    "    axes.set_ylabel('Gain')\n",
    "    axes.legend()\n",
    "    \n",
    "    if save:\n",
    "        if figname is None:\n",
    "            raise NotImplementedError('No file name given')\n",
    "        plt.savefig(f'{figname}.png', bbox_inches='tight')\n",
    "    \n",
    "def Plot2Gains(LoK1, LoK2, save=False, figname=None):\n",
    "    \n",
    "    K1,K2 = GainExtractor(LoK1)\n",
    "    K1_opt = -0.4634*np.ones(len(K1))\n",
    "    K2_opt = -1.0170*np.ones(len(K2))\n",
    "    K1_, K2_ = GainExtractor(LoK2)\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(dpi=200)\n",
    "    axes=fig.add_axes([0,0,1,1])\n",
    "\n",
    "    X = range(len(K1))\n",
    "\n",
    "    axes.plot(X,K1,'b',label='K_initial(1)')\n",
    "    axes.plot(X,K1_opt,'y')\n",
    "    axes.plot(X,K2,'b')\n",
    "    axes.plot(X,K2_opt,'y', label='LQR optimal gain')\n",
    "    axes.plot(X,K1_,'r',label='K_initial(2)')\n",
    "    axes.plot(X,K2_,'r')\n",
    "    axes.set_xlabel('Iteration Number')\n",
    "    axes.set_ylabel('Gain')\n",
    "    axes.legend()\n",
    "    \n",
    "    if save:\n",
    "        if figname is None:\n",
    "            raise NotImplementedError('No file name given')\n",
    "        plt.savefig(f'{figname}.png')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
